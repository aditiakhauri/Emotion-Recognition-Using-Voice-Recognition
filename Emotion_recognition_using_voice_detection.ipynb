{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qb8-Uj2ZNI9"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsXCkdnrZyGx"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bS3HAAuZ021"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FjQuJidZ4AB"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRaDNx9TZ693"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qorH49SUaLOL"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al_fUK0rajx-"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPJjRbwNapJc"
      },
      "outputs": [],
      "source": [
        "! unzip toronto-emotional-speech-set-tess.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHbQlIHGa-EB"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "from IPython.display  import Audio\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
        "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkh4XOz5dj0R"
      },
      "source": [
        "# **LOADING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzApvM_Vdn8p"
      },
      "outputs": [],
      "source": [
        "paths = []\n",
        "labels = []\n",
        "for dirname, _, filenames in os.walk('/content/TESS Toronto emotional speech set data'):\n",
        "    for filename in filenames:\n",
        "        paths.append(os.path.join(dirname, filename))\n",
        "        label = filename.split('_')[-1]\n",
        "        sas = filename.split('/')[-1].split('A')[0]\n",
        "        if sas == 'Y':\n",
        "            sas = 'Female_'\n",
        "        else:\n",
        "            sas = 'Male_'\n",
        "        label = label.split('.')[0]\n",
        "        label = sas + label\n",
        "        labels.append(label.lower())\n",
        "        print(label)\n",
        "    \n",
        "print('Dataset is Loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cEbMM5tfmAw"
      },
      "outputs": [],
      "source": [
        "len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcLEai8Wfoz8"
      },
      "outputs": [],
      "source": [
        "paths[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJCWLw_IfsuX"
      },
      "outputs": [],
      "source": [
        "labels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T6K9qk2fxAa"
      },
      "outputs": [],
      "source": [
        "## Create a dataframe\n",
        "df = pd.DataFrame()\n",
        "df['speech'] = paths\n",
        "df['label'] = labels\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uBOLfKof3jw"
      },
      "outputs": [],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKJtM_zAf8BZ"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEj0Q8f2f-mk"
      },
      "outputs": [],
      "source": [
        "def waveplot(data, sr, emotion):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.title(emotion, size=20)\n",
        "    librosa.display.waveplot(data, sr=sr)\n",
        "    plt.show()\n",
        "    \n",
        "def spectogram(data, sr, emotion):\n",
        "    x = librosa.stft(data)\n",
        "    xdb = librosa.amplitude_to_db(abs(x))\n",
        "    plt.figure(figsize=(11,4))\n",
        "    plt.title(emotion, size=20)\n",
        "    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "    plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86jQKrR9kwL6"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_fear'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMjTQOSH2TkU"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_fear'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ipczH00l5rK"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_angry'\n",
        "path = np.array(df['speech'][df['label']==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3-hZUaZ6tNP"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_angry'\n",
        "path = np.array(df['speech'][df['label']==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohEf9fECmnGc"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_disgust'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBPyjww57PmC"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_disgust'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omtuv5rCm_OF"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_neutral'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-_TAstU7svY"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_neutral'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vzJlDE8nQPj"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_sad'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyOVS4We9vg5"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_sad'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1JFfV8wnsBZ"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_ps'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4_J-vvO_t1P"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_ps'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrbWhERyoZeW"
      },
      "outputs": [],
      "source": [
        "emotion = 'female_happy'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdnzSPAFGlGO"
      },
      "outputs": [],
      "source": [
        "emotion = 'male_happy'\n",
        "path = np.array(df['speech'][df['label']==emotion])[0]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "librosa.display.waveshow(data,sr=sampling_rate)\n",
        "spectogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs9nqkPQY0RE"
      },
      "source": [
        "# **FEATURE EXTRACTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbCu_g1tY4Qa"
      },
      "outputs": [],
      "source": [
        "def extract_mfcc(filename):\n",
        "    y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    return mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t63SjdDVY8FT"
      },
      "outputs": [],
      "source": [
        "extract_mfcc(df['speech'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ed2L-5RZCRg"
      },
      "outputs": [],
      "source": [
        "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rbpkDRgZGFR"
      },
      "outputs": [],
      "source": [
        "X_mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUK4Vni9ZKhR"
      },
      "outputs": [],
      "source": [
        "X = [x for x in X_mfcc]\n",
        "X = np.array(X)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TLgsmieZOsf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "y = enc.fit_transform(df[['label']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbxZBm7FZTq0"
      },
      "outputs": [],
      "source": [
        "y = y.toarray()\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDc4affWS9BK"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(256, return_sequences=False, input_shape=(40,1)),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(14, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDpuqQscURn2"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X, y, validation_split=0.2, epochs=100, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxH7QBQSWmce"
      },
      "outputs": [],
      "source": [
        "epochs = list(range(100))\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, label='train accuracy')\n",
        "plt.plot(epochs, val_acc, label='val accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H0JZKs0Wwlj"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, loss, label='train loss')\n",
        "plt.plot(epochs, val_loss, label='val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jSoReb3XOeP"
      },
      "outputs": [],
      "source": [
        "list1 = df['label']\n",
        "print(list1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Xtrain, Ytrain, Xtest, Ytest = train_test_split(X, y, test_size= 0.3, random_state = 0)\n",
        "\n",
        "#Abhinav\n",
        "Xtrain, Xtest,YTrain, Ytest = train_test_split(X, y, test_size= 0.3, random_state = 0)\n",
        "\n",
        "Xtrain.shape, Xtest.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
